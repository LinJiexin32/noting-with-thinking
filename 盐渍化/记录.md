## 开发
Situation：构建Auto-BI : 基于文心一言的数据处理Agent

Task：

* 	使用python + Langchain框架，参与构建ReAct 类Agent。AutoBI Agent调度各种数据处理工具，实现对城市数据的自动处理和分析。
*  基于Pandas、Plotly等开源库及MySQL，为Agent 设计各种数据处理工具。包括数据筛选、数据可视化、生成总结性报告等工具，并集成到Auto- BI框架中以增强Agent的业务能力。
*  基于Streamlit框架，为各种数据处理工具开发配套的前端UI界面。让数据处理工具可由Agent调度，也可由用户点选。

## 算法设计
NL to Python模块的设计和实现

Situation：LLM基于自然语言prompt生成的代码无法应对复杂的数据分析任务，错误率高，且复用性差。人工为Agent配置数据处理工具又耗时耗力，需要更好地发挥LLM的代码生成能力。此外，AI生成式代码可能存在安全性问题，需要在隔离的环境中运行和调试。

设计思路：

模拟人类的思维方式，采取“分而治之”的策略。将复杂的数据处理任务分解成简单的子任务，利用LLM的代码生成能力为每个子任务生成代码。利用LLM的调度能力，调度各个子任务的代码以实现复杂的数据处理需求。同时，基于ReAct机制迭代评估各个子功能对应的代码的执行情况，实现自动Debug。之后，利用LLM的改写能力，将主函数封装成Agent标准工具类，以实现代码的复用。最后，利用LLM的总结能力，将上述过程生成总结性报告。

Task：

* 基于以上的设计思路，使用Langchain框架开发NL2Python模块
* 搭建Docker 容器，为NL2Python生成的代码提供运行的container并提取处理结果，避免生成式代码可能存在的安全性问题。
*  测试NL2Python 在“人口”、“经济”、“环境”等十余个数据集上的能力。
